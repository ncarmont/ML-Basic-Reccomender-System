{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW3 CSE158 - \n",
    "# Purchase and Category Predictor\n",
    "By Nicolas Carmont Zaragoza (A15677088)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.) TASK: Build negative sample set by randomly sampling 100k non-purchased user/item pairs (as so far we only have postive sample data). Then combine the 100k negative sample with the 100k positive sample to create the validation set and report its accuracy on the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in file and item/pair data\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "\n",
    "def readGz(f):\n",
    "  for l in gzip.open(f):\n",
    "    yield eval(l)\n",
    "    \n",
    "### Rating baseline: compute averages for each user, or return the global average if we've never seen the user before\n",
    "\n",
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "allData = list()\n",
    "\n",
    "for data in readGz(\"train.json.gz\"):\n",
    "    allData.append(data)\n",
    "    \n",
    "trnData = allData[:100000]\n",
    "validationData = allData[100000:]\n",
    "\n",
    "import random\n",
    "\n",
    "users1 = list(set(a['reviewerID'] for a in allData))  # convert to set to remove duplicate users\n",
    "items1 = list(set(a['itemID'] for a in allData))\n",
    "\n",
    "userItemPairs = set((a['reviewerID'],a['itemID']) for a in allData)\n",
    "\n",
    "      \n",
    "validationSet2 = set()\n",
    "while(len(validationSet2)!=100000):\n",
    "    userRand = random.choice(users1)\n",
    "    itemRand = random.choice(items1)\n",
    "    \n",
    "    if(((userRand,itemRand) not in userItemPairs) & ((userRand,itemRand) not in validationSet2)):\n",
    "        validationSet2.add((userRand,itemRand)) # check for duplicates                  \n",
    "        validationData.append({'reviewerID':userRand,'itemID':itemRand})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of baseline Q1:\n",
      "TP: 44482\n",
      "TN: 81392\n",
      "FN: 55518\n",
      "FP: 18608\n",
      "Total: 200000\n",
      "Accuracy: 0.62937\n"
     ]
    }
   ],
   "source": [
    "# Run baseline\n",
    "businessCount = defaultdict(int)\n",
    "totalPurchases = 0\n",
    "\n",
    "# for l in readGz(\"train.json.gz\"):\n",
    "for l in trnData:\n",
    "    user,business = l['reviewerID'],l['itemID']\n",
    "    businessCount[business] += 1\n",
    "    totalPurchases += 1\n",
    "\n",
    "mostPopular = [(businessCount[x], x) for x in businessCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalPurchases/2:  \n",
    "        break\n",
    "# print(len(return1))\n",
    "\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "\n",
    "# predictions = open(\"predictions_Purchase.txt\", 'w')\n",
    "for j in range(0,len(validationData)):\n",
    "    u,i = validationData[j]['reviewerID'],validationData[j]['itemID']\n",
    "    if ((i in return1) & (j<100000)):\n",
    "        TP+=1\n",
    "    elif ((i in return1) & (j>=100000)):\n",
    "        FP+=1\n",
    "    elif((i not in return1) & (j>=100000)):\n",
    "        TN+=1\n",
    "    elif((i not in return1) & (j<100000)):\n",
    "        FN+=1\n",
    "        \n",
    "print(\"Performance of baseline Q1:\")      \n",
    "print(\"TP: \" + str(TP))\n",
    "print(\"TN: \" +str(TN))\n",
    "print(\"FN: \" +str(FN))\n",
    "print(\"FP: \" + str(FP))\n",
    "total = TP+FP+FN+TN\n",
    "print(\"Total: \"+ str(total))\n",
    "accuracy = (TP+TN)/total\n",
    "print(\"Accuracy: \" + str(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.) TASK:The current purchase prediction baseline return True if an item is within the top 50th percentile of popularity. Is this threshold the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of baseline Q2:\n",
      "TP: 97797\n",
      "TN: 2727\n",
      "FN: 2203\n",
      "FP: 97273\n",
      "Total: 200000\n",
      "Accuracy: 0.50262\n"
     ]
    }
   ],
   "source": [
    "# Run Baseline with different threshold values\n",
    "businessCount = defaultdict(int)\n",
    "totalPurchases = 0\n",
    "\n",
    "# for l in readGz(\"train.json.gz\"):\n",
    "for l in trnData:\n",
    "    user,business = l['reviewerID'],l['itemID']\n",
    "    businessCount[business] += 1\n",
    "    totalPurchases += 1\n",
    "\n",
    "mostPopular = [(businessCount[x], x) for x in businessCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalPurchases/0.5:  # 0.1, 0.5, 0.8, 2,3, 10, 200, 10000 change values\n",
    "        break\n",
    "\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "\n",
    "for j in range(0,len(validationData)):\n",
    "    u,i = validationData[j]['reviewerID'],validationData[j]['itemID']\n",
    "    if ((i in return1) & (j<100000)):\n",
    "        TP+=1\n",
    "    elif ((i in return1) & (j>=100000)):\n",
    "        FP+=1\n",
    "    elif((i not in return1) & (j>=100000)):\n",
    "        TN+=1\n",
    "    elif((i not in return1) & (j<100000)):\n",
    "        FN+=1\n",
    "\n",
    "print(\"Performance of baseline Q2:\") \n",
    "print(\"TP: \" + str(TP))\n",
    "print(\"TN: \" +str(TN))\n",
    "print(\"FN: \" +str(FN))\n",
    "print(\"FP: \" + str(FP))\n",
    "total = TP+FP+FN+TN\n",
    "print(\"Total: \"+ str(total))\n",
    "accuracy = (TP+TN)/total\n",
    "print(\"Accuracy: \" + str(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: Increasing the value of the threshold (with a smaller  denominator of 0.1 and 0.5) seemed to decrease the accuracy of our purchase predictor closer and closer towards 0.5 (which is equivalent to random prediction). Similarly, decreasing the threshold (with a larger denominator of 3, 10, 200,10000) seemed to also decrease the accuaracy of our predictor closer and closer to 0.5.\n",
    "\n",
    "With our validation set being biased with a perfect even split of positives (100k) and negative entries(100k), a threshold = 0.5 seems to be the best benchmark for the model. This is because at a Threshold = 0.5 the model is not skewed to have too many FP (which are created if we reduced the threshold below 0.5 because it classifies too many as Positive), and not skewed to have too many FN ( which are created if we increases the threshold above 0.5 because its classified too many as negative). In the end with our 100k non-purchased items being randomly selected and our positives and negative entries being equal in the validation set, it makes sense that we want to have a threshold which parts the training data popularity evenly to best fit the validation data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.) TASK: As users tend to repeatedly purchase items of the same type, build a baseline that returns 'True' if a user has purchased an item of the same category before or zero otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of categories every user has bought\n",
    "userCatg = dict()\n",
    "for i in trnData:  # allData: \n",
    "    userCatg[i['reviewerID']] = list()\n",
    "    \n",
    "# Makes list of categories each user has purchased\n",
    "for i in trnData:      \n",
    "    userCatg[i['reviewerID']].append(i['categoryID'])\n",
    "\n",
    "itemCatg = dict()\n",
    "# Assigns category to each item\n",
    "for i in trnData: #allData: \n",
    "      itemCatg[i['itemID']] = i['categoryID']\n",
    "\n",
    "# write predictions into file\n",
    "predictions = open(\"predictions_Purchase.txt\", 'w')\n",
    "for l in open(\"pairs_purchase.txt\"):\n",
    "    if l.startswith(\"reviewerID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    \n",
    "    # check if user has bough category and item category has been seen before\n",
    "    if((u in userCatg.keys()) & (i in itemCatg.keys())):\n",
    "        uCat = userCatg[u]\n",
    "        iCat = itemCatg[i]\n",
    "        if iCat in uCat:\n",
    "            predictions.write(u + '-' + i + \",1\\n\")\n",
    "        else:\n",
    "            predictions.write(u + '-' + i + \",0\\n\") \n",
    "    else:\n",
    "        predictions.write(u + '-' + i + \",0\\n\") # predict as false if user or item has not been seen before        \n",
    "predictions.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4.) TASK: Upload Solution to and baseline from Q3 to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: My Kaggle username is: nickcarmont   \n",
    "     Score acheived with trnData: 59.7000  \n",
    "     Max score with all data: 0.6000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5.) TASK: Build training/validation sets with only reviews that have a 'categoryID' field. These are reviews that had exactly one of the 5 categories selected, so that there is no ambiguity in their category label (the test reviews also have only a single, unambigious category).\n",
    "\n",
    "A trivial predictor might assume that each user tends to purchase only one category of item. For each user in the training set, identify  the category of item they purchased most freq (in case of tie, choose which categ is most popular overall). Then, for each revirew in your validation set, simply return whicever category you identified as being the most popular (otherwise return 0 if you've never seen the user before). Report the performance of this classifier on the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most popular categories overall: {0: 70878, 1: 25512, 2: 1178, 3: 925, 4: 1507}\n",
      "correct: 80174\n",
      "wrong: 19826\n",
      "total: 100000\n",
      "accuracy: 0.80174\n"
     ]
    }
   ],
   "source": [
    "allDataWCateg = list()\n",
    "\n",
    "# Filter all data for only data with 'categoryID'\n",
    "for a in allData:       \n",
    "    if 'categoryID' in a.keys():\n",
    "        allDataWCateg.append(a)\n",
    "        \n",
    "# part data equally amongst train and val (100k each)      \n",
    "lenDataCateg = int(len(allDataWCateg)/2)\n",
    "trnData2 = allDataWCateg[:lenDataCateg]  \n",
    "valData = allDataWCateg[lenDataCateg:]\n",
    "\n",
    "\n",
    "# sub-sample data for testing\n",
    "# trnData2 = trnData2[:20000]  # part data equally amongst train and val\n",
    "# valData = allDataWCateg[180000:]\n",
    "# print(len(trnData2))\n",
    "# print(len(valData))\n",
    "\n",
    "# most popular categories\n",
    "categOverallQ5 = {0:0,1:0,2:0,3:0,4:0}\n",
    "for a in trnData2:\n",
    "    categOverallQ5[a['categoryID']]+=1\n",
    "print(\"most popular categories overall: \" + str(categOverallQ5))\n",
    "\n",
    "# most frequent category by user\n",
    "userCatgMostF = dict()\n",
    "for i in trnData2:\n",
    "    userCatgMostF[i['reviewerID']] = {0:0,1:0,2:0,3:0,4:0}\n",
    "for i in trnData2:\n",
    "    userCatgMostF[i['reviewerID']][i['categoryID']] += 1\n",
    "    \n",
    "# List of users in trn data without duplicates\n",
    "users5 = list(set(a['reviewerID'] for a in trnData2))\n",
    "\n",
    "\n",
    "preds = list()\n",
    "\n",
    "for a in valData:\n",
    "    \n",
    "    # check if user has been seen before in trn data\n",
    "    if(a['reviewerID'] in users5):\n",
    "        \n",
    "        # Get index of most popular category of user\n",
    "        indMaxVal = max(userCatgMostF[a['reviewerID']], key=userCatgMostF[a['reviewerID']].get)\n",
    "       \n",
    "        # in case of tie, return most popular categ overall\n",
    "        equalEntries = list()\n",
    "        equalEntries = []\n",
    "        for i in range(0,5):   # Check for no ties, if ties add to equalEntries\n",
    "            if((userCatgMostF[a['reviewerID']][indMaxVal]) == (userCatgMostF[a['reviewerID']][i])):\n",
    "                equalEntries.append(i)\n",
    "                \n",
    "        # if equal entries, find max overall\n",
    "        if(len(equalEntries)>1):\n",
    "            maxOver = 0\n",
    "            winCateg = 0\n",
    "            for j in equalEntries:\n",
    "                if (maxOver <= categOverallQ5[j]):\n",
    "                    maxOver = categOverallQ5[j]\n",
    "                    winCateg = j\n",
    "                    indMaxVal = winCateg   # set indMaxVal to most popular overall in tie\n",
    "        # Append max to predictions\n",
    "        preds.append(indMaxVal)\n",
    "    else:\n",
    "        preds.append(0)\n",
    "        \n",
    "wrong = 0\n",
    "corr = 0\n",
    "\n",
    "# Compare predictions to actual 'CategoryID'\n",
    "for i in range(0,len(valData)):\n",
    "    if (valData[i]['categoryID'] == preds[i]):\n",
    "        corr+=1\n",
    "    else:\n",
    "        wrong+=1\n",
    "\n",
    "print(\"correct: \" +str(corr))\n",
    "print(\"wrong: \" + str(wrong))\n",
    "total = corr + wrong\n",
    "print(\"total: \"  +str(total))\n",
    "acc = corr/total\n",
    "print(\"accuracy: \"+ str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6.) TASK: We will now look for the presence of common words. We start by removing punctuation and capitalization and finding the 500 most common words across all reviews ('reviewText' field) in the training set. See the 'text mining' lectures for the code for this process\n",
    "\n",
    "The most common words probably don't do much help for us to predict categories. Instead, we'll find which words are more common in each category compared to the others. First, we'll compute the frequency of the 500 words you just found as follows:\n",
    "\n",
    "freq_word = (# times words appears)/(sum of # of items the i_th most popular word appears)\n",
    "\n",
    "Next, we'll compute the freq per category,e.g:\n",
    "\n",
    "freq[Women]_word = (# of times words appears in 'Women's clothing' reviews)/ (sum of times the i_th most popular word appears in 'W's Clothing' reviews)\n",
    "\n",
    "With this computed, we can find which words are more popular in one category compared to their overall frequenyc across categories.i.e\n",
    "\n",
    "freq['Women's clothing']_word - freq_word\n",
    "\n",
    "Report for each of the 5 categories the 10 words that are more frequent in that category compared to the other categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 words more frequent in each category than the rest:\n",
      "Women (category 0) : ['i', 'in', 'but', 'have', 'not', 'with', 'like', 'wear', 'love', 'comfortable']\n",
      "Men (category 1): ['the', 'a', 'to', 'of', 'that', 'you', 'good', 'or', 'if', 'more']\n",
      "Girls (category  2): ['it', 'is', 'this', 'be', 'would', 'its', 'one', 'price', 'small', 'looks']\n",
      "Boys (category 3): ['for', 'my', 'was', 'size', 'fit', 'great', '', 'well', 'up', 'nice']\n",
      "Baby (category 4): ['and', 'they', 'are', 'these', 'on', 'them', 'so', 'very', 'as', 'just']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "punct = set(string.punctuation)\n",
    "wordC = defaultdict(int)\n",
    "\n",
    "trnData = allData[:100000]\n",
    "# Remove punctuation and convert to lower case\n",
    "for a in trnData:  # classify with training data\n",
    "    for wrd in a['reviewText'].split():\n",
    "        if(wrd == ''):\n",
    "            continue\n",
    "        else:\n",
    "            wrd = ''.join([char for char in wrd.lower() if not char in punct])\n",
    "            wordC[wrd] += 1\n",
    "# print (len(wordC))\n",
    "\n",
    "wordCRm = wordC\n",
    "top500 = dict()\n",
    "\n",
    "while (len(top500)!= 500):\n",
    "\n",
    "   # Find max in keys\n",
    "    maxFWord = max(wordCRm, key=wordCRm.get)    \n",
    "    cWord = wordCRm[maxFWord]\n",
    "    \n",
    "    # Add max to new list\n",
    "    top500.update({maxFWord : cWord})\n",
    "\n",
    "    # Remove max from old list\n",
    "    wordCRm.pop(maxFWord)\n",
    "\n",
    "# Calculate sum # of times the ith most pop word appears\n",
    "totalAppTop500 = sum(list(top500.values()))\n",
    "\n",
    "# Make list of frequencies of top 500 words\n",
    "fTop500 = dict()\n",
    "for a in top500:\n",
    "    freqWord = (top500[a])/(totalAppTop500)\n",
    "    fTop500.update({a:freqWord})\n",
    "    \n",
    "# Compute relative frequency of words by category\n",
    "\n",
    "# find number of times word appears in Categ\n",
    "punct = set(string.punctuation)\n",
    "wordCat0 = defaultdict(int)\n",
    "wordCat1 = defaultdict(int)\n",
    "wordCat2 = defaultdict(int)\n",
    "wordCat3 = defaultdict(int)\n",
    "wordCat4 = defaultdict(int)\n",
    "\n",
    "totalWC0 =0\n",
    "totalWC1 =0\n",
    "totalWC2 =0\n",
    "totalWC3 =0\n",
    "totalWC4 =0\n",
    "\n",
    "trnData = allData[:100000]\n",
    "\n",
    "# Find top 500 words freq in each category  \n",
    "# [ SORRY had to do this the long was as I had errors the other way]\n",
    "for a in trnData:  # classify with training data\n",
    "    for wrd in a['reviewText'].split():\n",
    "        if(a['categoryID']==0):\n",
    "            if(wrd != ''):\n",
    "                wrd = ''.join([char for char in wrd.lower() if not char in punct])\n",
    "                if(wrd in (list(fTop500.keys()))):\n",
    "                    wordCat0[wrd] += 1\n",
    "                    totalWC0 +=1\n",
    "        elif(a['categoryID']==1):\n",
    "            if(wrd != ''):\n",
    "                wrd = ''.join([char for char in wrd.lower() if not char in punct])\n",
    "                if(wrd in (list(fTop500.keys()))):\n",
    "                    wordCat1[wrd] += 1\n",
    "                    totalWC1 +=1\n",
    "        elif(a['categoryID']==2):\n",
    "            if(wrd != ''):\n",
    "                wrd = ''.join([char for char in wrd.lower() if not char in punct])\n",
    "                if(wrd in (list(fTop500.keys()))):\n",
    "                    wordCat2[wrd] += 1\n",
    "                    totalWC2 +=1\n",
    "        elif(a['categoryID']==3):\n",
    "            if(wrd != ''):\n",
    "                wrd = ''.join([char for char in wrd.lower() if not char in punct])\n",
    "                if(wrd in (list(fTop500.keys()))):\n",
    "                    wordCat3[wrd] += 1\n",
    "                    totalWC3 +=1\n",
    "        elif(a['categoryID']==4):\n",
    "            if(wrd != ''):\n",
    "                wrd = ''.join([char for char in wrd.lower() if not char in punct])\n",
    "                if(wrd in (list(fTop500.keys()))):\n",
    "                    wordCat4[wrd] += 1\n",
    "                    totalWC4 +=1\n",
    "                    \n",
    "# Find comparative frequency of top500 words in each category            \n",
    "for a in list(fTop500.keys()):\n",
    "    total0 = (wordCat0[a]/totalWC0) - fTop500[a]\n",
    "    wordCat0.update({a:total0 })\n",
    "    \n",
    "    total1 = (wordCat1[a]/totalWC1) - fTop500[a]\n",
    "    wordCat1.update({a:total1 })\n",
    "    \n",
    "    total2 = (wordCat2[a]/totalWC2) - fTop500[a]\n",
    "    wordCat2.update({a:total2 })\n",
    "    \n",
    "    total3 = (wordCat3[a]/totalWC3) - fTop500[a]\n",
    "    wordCat3.update({a:total3 })\n",
    "    \n",
    "    total4 = (wordCat4[a]/totalWC4) - fTop500[a]\n",
    "    wordCat4.update({a:total4})\n",
    "\n",
    "w10Cat0 = list()\n",
    "w10Cat1 = list()\n",
    "w10Cat2 = list()\n",
    "w10Cat3 = list()\n",
    "w10Cat4 = list()\n",
    "    \n",
    "# Find 10 words more frequent in every category compared to all others\n",
    "while(len(w10Cat0)!=10):\n",
    "    for a in list(fTop500.keys()):\n",
    "        if((len(w10Cat0)<10)&((wordCat0[a]) > (wordCat1[a])) & ((wordCat0[a]) > (wordCat2[a])) & ((wordCat0[a]) > (wordCat3[a])) & ((wordCat0[a]) > (wordCat4[a]))):\n",
    "              w10Cat0.append(a)\n",
    "\n",
    "while(len(w10Cat1)!=10):\n",
    "    for a in list(fTop500.keys()):\n",
    "        if((len(w10Cat1)<10)&((wordCat1[a]) > (wordCat0[a])) & ((wordCat1[a]) > (wordCat2[a])) & ((wordCat1[a]) > (wordCat3[a])) & ((wordCat1[a]) > (wordCat4[a]))):\n",
    "              w10Cat1.append(a)\n",
    "                \n",
    "while(len(w10Cat2)!=10):\n",
    "    for a in list(fTop500.keys()):\n",
    "        if((len(w10Cat2)<10)&((wordCat2[a]) > (wordCat1[a])) & ((wordCat2[a]) > (wordCat0[a])) & ((wordCat2[a]) > (wordCat3[a])) & ((wordCat2[a]) > (wordCat4[a]))):\n",
    "              w10Cat2.append(a)\n",
    "\n",
    "while(len(w10Cat3)!=10):\n",
    "    for a in list(fTop500.keys()):\n",
    "        if((len(w10Cat3)<10)&((wordCat3[a]) > (wordCat1[a])) & ((wordCat3[a]) > (wordCat2[a])) & ((wordCat3[a]) > (wordCat0[a])) & ((wordCat3[a]) > (wordCat4[a]))):\n",
    "              w10Cat3.append(a)\n",
    "\n",
    "while(len(w10Cat4)!=10):\n",
    "    for a in list(fTop500.keys()):\n",
    "        if((len(w10Cat4)<10)&((wordCat4[a]) > (wordCat1[a])) & ((wordCat4[a]) > (wordCat2[a])) & ((wordCat4[a]) > (wordCat3[a])) & ((wordCat4[a]) > (wordCat0[a]))):\n",
    "              w10Cat4.append(a)\n",
    "                \n",
    "print(\"10 words more frequent in each category than the rest:\")            \n",
    "print(\"Women (category 0) : \" +str(w10Cat0))\n",
    "print(\"Men (category 1): \" +str(w10Cat1))\n",
    "print(\"Girls (category  2): \" +str(w10Cat2))\n",
    "print(\"Boys (category 3): \" +str(w10Cat3))\n",
    "print(\"Baby (category 4): \" +str(w10Cat4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7.) TASK: Now we'll run some classifiers by  building a simple feature vector out of our 500 most popular words as follows:\n",
    "[commonWords[0] in review, commonWords[1] in review,..., commonWords[499] in review]\n",
    "\n",
    "We will train an SVM to distinguish Women's clothing and non-women's clothing only. That is, discard all other categories from the training set in order to train a binary classifier, but keep them in the validation set ( your classifier will simply be wrong for those instances). Train for C (= 0.01, 0.1, 1,10,100), the regularisation parameter for the SVM, and report the best performance you obtain on  the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length Training Data: 10000\n",
      "length Validation Data: 10000\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "trnData = allData[:100000]\n",
    "# Check if categ and review values are in trnData\n",
    "trnData = [x for x in trnData if 'reviewText' in x if 'categoryID' in x]\n",
    "\n",
    "# Change C-value and find highest accuracy on val Data\n",
    "cVal = 100\n",
    "\n",
    "# Sub-sample training data to 10% for testing\n",
    "random.shuffle(trnData)\n",
    "trnData  = trnData[90000:]\n",
    "print(\"length Training Data: \" +str(len(trnData)))\n",
    "\n",
    "\n",
    "# Sub-sample validation data to 10% for testing\n",
    "random.shuffle(validationData)\n",
    "validationData  = validationData[190000:]\n",
    "print(\"length Validation Data: \"+str(len(validationData)))\n",
    "\n",
    "def isWomenClothing(dataIn):\n",
    "    if dataIn['categoryID'] == 0:\n",
    "        isW = 1 \n",
    "    else:\n",
    "        isW = 0 \n",
    "    return isW\n",
    "\n",
    "def isWordInReview(dataIn, word):\n",
    "    if word in dataIn:\n",
    "        return 1 \n",
    "    else:\n",
    "        return 0 \n",
    "\n",
    "def features(dataIn):\n",
    "    feat = list()\n",
    "    for a in list(fTop500.keys()):\n",
    "         feat.append(isWordInReview(dataIn['reviewText'],a))                                                                                 \n",
    "    return feat\n",
    "\n",
    "# Test Data in features\n",
    "xClass= [features(b) for b in trnData]\n",
    "yClass= [isWomenClothing(w) for w in trnData]\n",
    "\n",
    "# SVM linear Classifier\n",
    "wClassifier = svm.SVC(C=cVal, kernel='linear')\n",
    "wClassifier.fit(xClass, yClass)\n",
    "\n",
    "# Validation data\n",
    "xVal= [features(b) for b in validationData]\n",
    "yVal= [w['categoryID'] for w in validationData]\n",
    "\n",
    "predClassTst = wClassifier.predict(xVal)\n",
    "print(\"accuracy for C= \" +str(cVal)+\" : \"+str(accuracy_score(yVal, predClassTst)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: As commented by the TA's I ran my model using the different C values of 0.01,0.1,1,10,100 on the 10% sampled data. As the SVM was taking too long to run on the full data set.   \n",
    "  \n",
    "Given this, I found that a C value (regularization paramter) of 0.1 lead to the highest accuracy for the SVM of Acc = 0.8174.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8.) TASK: Rather than training a binary SVM, train 5 SVM's that distinguish each category from all other categories. Again selecting different values for C (= 0.01, 0.1, 1, 10, 100) for each classifier. For the validation set, classify each point according to whichever of the five classifiers is most confident about the label being positive (use 'decision_function' in  the SVM lib). Report the performance of this classifier on the validation set and upload the solution to Kaggle by running it on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make functions distinguishing category y data for each SVM\n",
    "\n",
    "def isMenClothing(dataIn):\n",
    "    if dataIn['categoryID'] == 1:\n",
    "        isC = 1 \n",
    "    else:\n",
    "        isC = 0 \n",
    "    return isC\n",
    "\n",
    "def isGirlClothing(dataIn):\n",
    "    if dataIn['categoryID'] == 2:\n",
    "        isC = 1 \n",
    "    else:\n",
    "        isC = 0 \n",
    "    return isC\n",
    "\n",
    "def isBoyClothing(dataIn):\n",
    "    if dataIn['categoryID'] == 3:\n",
    "        isC = 1 \n",
    "    else:\n",
    "        isC = 0 \n",
    "    return isC\n",
    "\n",
    "def isBabyClothing(dataIn):\n",
    "    if dataIn['categoryID'] == 4:\n",
    "        isC = 1 \n",
    "    else:\n",
    "        isC = 0 \n",
    "    return isC\n",
    "\n",
    "\n",
    "# SVM 1 for Women's Clothing: \n",
    "\n",
    "cVal = 0.01\n",
    "xClass= [features(b) for b in trnData]\n",
    "yClass= [isWomenClothing(w) for w in trnData]\n",
    "\n",
    "# SVM linear Classifier\n",
    "wClassifier = svm.SVC(C=cVal, kernel='linear')\n",
    "wClassifier.fit(xClass, yClass)\n",
    "\n",
    "# Validation data\n",
    "xVal= [features(b) for b in validationData]\n",
    "yVal= [w['categoryID'] for w in validationData]\n",
    "\n",
    "predClassTst = wClassifier.predict(xVal)\n",
    "print(\"accuracy for C= \" +str(cVal)+\" : \"+str(accuracy_score(yVal, predClassTst)))\n",
    "\n",
    "\n",
    "# SVM 2 for Mens's Clothing:\n",
    "\n",
    "cVal = 100\n",
    "yClass= [isMenClothing(w) for w in trnData]\n",
    "\n",
    "# SVM linear Classifier\n",
    "mClassifier = svm.SVC(C=cVal, kernel='linear')\n",
    "mClassifier.fit(xClass, yClass)\n",
    "\n",
    "# Validation data\n",
    "xVal= [features(b) for b in validationData]\n",
    "yVal= [w['categoryID'] for w in validationData]\n",
    "\n",
    "predClassTst = mClassifier.predict(xVal)\n",
    "print(\"accuracy for C= \" +str(cVal)+\" : \"+str(accuracy_score(yVal, predClassTst)))\n",
    "\n",
    "\n",
    "# SVM 3 for Girls's Clothing:\n",
    "\n",
    "cVal = 0.1\n",
    "yClass= [isGirlClothing(w) for w in trnData]\n",
    "\n",
    "# SVM linear Classifier\n",
    "gClassifier = svm.SVC(C=cVal, kernel='linear')\n",
    "gClassifier.fit(xClass, yClass)\n",
    "\n",
    "# Validation data\n",
    "xVal= [features(b) for b in validationData]\n",
    "yVal= [w['categoryID'] for w in validationData]\n",
    "\n",
    "predClassTst = gClassifier.predict(xVal)\n",
    "print(\"accuracy for C= \" +str(cVal)+\" : \"+str(accuracy_score(yVal, predClassTst)))\n",
    "\n",
    "\n",
    "# SVM 4 for Boys's Clothing:\n",
    "\n",
    "cVal = 10\n",
    "yClass= [isBoyClothing(w) for w in trnData]\n",
    "\n",
    "# SVM linear Classifier\n",
    "bClassifier = svm.SVC(C=cVal, kernel='linear')\n",
    "bClassifier.fit(xClass, yClass)\n",
    "\n",
    "# Validation data\n",
    "xVal= [features(b) for b in validationData]\n",
    "yVal= [w['categoryID'] for w in validationData]\n",
    "\n",
    "predClassTst = bClassifier.predict(xVal)\n",
    "print(\"accuracy for C= \" +str(cVal)+\" : \"+str(accuracy_score(yVal, predClassTst)))\n",
    "\n",
    "\n",
    "# SVM 5 for Boys's Clothing:\n",
    "\n",
    "cVal = 0.01\n",
    "yClass= [isBabyClothing(w) for w in trnData]\n",
    "\n",
    "# SVM linear Classifier\n",
    "bbClassifier = svm.SVC(C=cVal, kernel='linear')\n",
    "bbClassifier.fit(xClass, yClass)\n",
    "\n",
    "# Validation data\n",
    "xVal= [features(b) for b in validationData]\n",
    "yVal= [w['categoryID'] for w in validationData]\n",
    "\n",
    "predClassTst = bbClassifier.predict(xVal)\n",
    "print(\"accuracy for C= \" +str(cVal)+\" : \"+str(accuracy_score(yVal, predClassTst)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
